{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadavo11/AI-CNN-X-ray-Cardiomegali-Detector/blob/main/ColabT3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Names:\n",
        "\n",
        "*   Tomer Siboni,       316532282\n",
        "*   Nadav Orenshtein,   312349509\n",
        "*   Lior Avadyayev,     *********\n",
        "\n",
        "Project Title:\n",
        "\n",
        "CNN - X-Ray Pathology Diagnoser\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U9medidXoeNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "In the past few decades, X-Ray images is widely used in order to diagnose medical issues, as fractures and pathologies. The use of this technology expands, and simply require a both proffesional and experienced examine of the images for each patient. While the theoretical and some practical knowledge has been given to us in the current course, it makes sense to use a given dataset to train a computing model to do the job, saving time and may be more efficient than the average radiologist. \n",
        "\n",
        "The model we train in this project is going to detect chest pathologies. We will use the information of the images themselves with a multilayered CNN, and as well some more variables referring to the patient is being included in the train and may potentially be important to make decisions about pathologies. For example, some pathologies may be more common with older people, and as well women breast may affect in certain ways on the model analysis of the image.\n"
      ],
      "metadata": {
        "id": "E3rMANdqqCY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "The data source for this project is located at kaggle website, and including close to 45,000 X-Ray images.\n",
        "Our dataset consisted of images of groups of 14 different diseases and one “no findings”, each image including the patient’s index, age and gender.\n",
        "While looking at the data, we noticed that some of the patients have more than one diagnose, which means that it will be difficult to check all the diseases in one NN and receive a reliable output for each, so at first we decided to check only one disease named “cardiomegaly” (enlarged heart), and get a true/false answer for it, it will be an easier task and we can get information that will help us to deal with the rest of the diseases.\n"
      ],
      "metadata": {
        "id": "xdNpKjjjxwzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data reaching process: ADD EXPLANATION\n",
        "\n"
      ],
      "metadata": {
        "id": "xtoo16ZVynjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gn04oEp0_lRK",
        "outputId": "e3d4563c-f4e8-412c-94d5-cc1547c2902c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from opendatasets) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (2.25.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle->opendatasets) (8.0.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "WqNnYR70wWZz",
        "outputId": "e95d69bf-0e74-4da1-becd-5c7312047602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "from glob import glob\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "import random\n",
        "from skimage.transform import resize\n",
        "import cv2\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "3Eoechuowmci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 72\n",
        "torch.manual_seed(seed)         \n",
        "torch.cuda.manual_seed(seed)    "
      ],
      "metadata": {
        "id": "RpkCG5tQwYso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "\t\"https://www.kaggle.com/datasets/nih-chest-xrays/data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Mib2mfvOAxrE",
        "outputId": "d367310b-f41f-410a-eee2-bce2ec8489ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: "
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a26148e866f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m od.download(\n\u001b[0m\u001b[1;32m      5\u001b[0m \t\"https://www.kaggle.com/datasets/nih-chest-xrays/data\")\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/opendatasets/__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check for a Kaggle dataset URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_kaggle_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Check for Google Drive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/opendatasets/utils/kaggle_api.py\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_url, data_dir, force, dry_run)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mread_kaggle_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_USERNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your Kaggle username\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_kaggle_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##☕ **Loading the dataset & preprocessing the data**\n",
        "\n",
        "Pre-processing the data is an important step in the process of building an AI that can detect pathologies in X-ray images. Proper pre-processing can help improve the performance of the model by ensuring that the data is in a consistent and suitable format for the machine learning algorithm.\n",
        "\n",
        "Let's get the X-ray scans and the lables from the NIH dataset, analyze it and preprocess it"
      ],
      "metadata": {
        "id": "bPNGd20mU6qV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df = pd.read_csv('data/Data_Entry_2017.csv')\n",
        "all_image_paths = {os.path.basename(x): x for x in \n",
        "                   glob(os.path.join('data', 'images*', '*', '*.png'))}\n",
        "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
        "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
        "#all_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x[:-1]))\n",
        "all_xray_df.sample(3)"
      ],
      "metadata": {
        "id": "OiX77p8MB7KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Standardizing the Patient Age\n",
        "Examining the data brought us to the decision of standardizing the age of the patiences. Adjusting the mean to 0, and the standard deviation to 1 is a common way to make the model optimization unaffected of the scale of the data, while improving its efficiency. It is more suitable for data that is already distributed similarly to a gaussian distribution.\n",
        "In the case of age it is not obvious that it would be a gaussian distribution, considering that heart diseases were thought to be common for elders. Making a histogram for the age distribution made it clear that the distribution is similar to a gaussian distribution, as shown in the figure below.\n",
        "\n"
      ],
      "metadata": {
        "id": "LVkWe6boCEPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = np.mean(all_xray_df['Patient Age'])\n",
        "sigma = np.std(all_xray_df['Patient Age'])\n",
        "print(sigma)\n",
        "\n",
        "\n",
        "plt.hist(all_xray_df['Patient Age'], bins=500)\n",
        "\n",
        "plt.gca().set(title='age Histogram', ylabel='Frequency',xlabel = 'age');\n",
        "plt.xlim([0, 100])\n",
        "\n",
        "x_data = np.arange(0, 100, 0.001)\n",
        "\n",
        "## y-axis as the gaussian\n",
        "y_data = stats.norm.pdf(x_data, mu, sigma)*len(all_xray_df['Patient Age'])\n",
        "\n",
        "\n",
        "plt.plot(x_data,y_data)\n",
        "plt.legend([\"gaussian curve\",\"age histogram\"])"
      ],
      "metadata": {
        "id": "rTtP57xWCHIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The histogram is seem to be close enough to the gaussian curve.\n",
        " \n",
        "Therefore, we would like to standardize the age such that  $\\mu = 0$ , $\\sigma = 1$"
      ],
      "metadata": {
        "id": "eQHeX2WgCOi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'𝜇 = {mu},\\t 𝜎 = {sigma}')\n",
        "\n",
        "all_xray_df['Patient Age'] = (all_xray_df['Patient Age'])/ sigma - mu/sigma\n"
      ],
      "metadata": {
        "id": "EAkdg6QBCPyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now compute and display the new $\\mu $ and $\\sigma $\n"
      ],
      "metadata": {
        "id": "pmPfMnfxCaow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mu = np.mean(all_xray_df['Patient Age'])\n",
        "sigma = np.std(all_xray_df['Patient Age'])\n",
        "\n",
        "print(f'𝜇 = {mu},\\t 𝜎 = {sigma}')"
      ],
      "metadata": {
        "id": "xcG_HWKECV3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's view the difference in our dataset"
      ],
      "metadata": {
        "id": "iL3PLKpTCtyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df.sample(3)\n"
      ],
      "metadata": {
        "id": "-KwM7jnvC0J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjusting the output\n",
        "Here we take the labels and make them into a more clear format. what's most important for us right now is to devide our label values into 2: \"Cardiomegaly\" diagnosed or \"No finding\"."
      ],
      "metadata": {
        "id": "Lwy-q5loC7eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df['Finding Labels'] = [x.split(\"|\") for x in all_xray_df['Finding Labels']]\n"
      ],
      "metadata": {
        "id": "8Y_lEh_qDGcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df['Cardiomegaly'] = [('Cardiomegaly' in x)*1 for x in all_xray_df['Finding Labels']]\n",
        "all_xray_df['No Finding'] = [('No Finding' in x)*1 for x in all_xray_df['Finding Labels']]\n",
        "\n",
        "print(f\"number of patients diagnosed with cardiomegaly: {np.sum(all_xray_df['Cardiomegaly'])}\")\n",
        "print(f\"number of patients diagnosed with No Finding: {np.sum(all_xray_df['No Finding'])}\")"
      ],
      "metadata": {
        "id": "4l_cKJdKDJqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_cardio = [plt.imread(all_xray_df['path'][i]) for i in range(4)]\n",
        "# plt.imshow(with_cardio,cmap = 'bone')\n",
        "\n",
        "\n",
        "fig, m_axs = plt.subplots(2, 2,figsize = (16, 16))\n",
        "fig.suptitle('first 4 patients')\n",
        "\n",
        "for i, ax in enumerate(m_axs.flatten()):\n",
        "    \n",
        "    print(all_xray_df['Cardiomegaly'][i])\n",
        "    ax.imshow(with_cardio[i],cmap = 'bone')\n",
        "    ax.set_title(f\"{'NOT'*(not all_xray_df['Cardiomegaly'][i])} diagnozed with Cardiomegaly\")\n",
        "\n"
      ],
      "metadata": {
        "id": "kWjJmHY1DN5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to resize the image so we check the image features for (224,224)"
      ],
      "metadata": {
        "id": "z1ZpvMMFpY73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = plt.imread(all_xray_df['path'][0])\n",
        "img=resize(img,(224,224))\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "5mTPX8eTl1Ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_xray_df['Gender'] =  [0 if g =='M' else 1 for g in all_xray_df['Patient Gender']]\n",
        "all_xray_df['position'] =  [0 if g =='AP' else 1 for g in all_xray_df['View Position']]\n",
        "all_xray_df.sample(3)"
      ],
      "metadata": {
        "id": "diuVF_9tJOZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the balanced Cardiomegali dataset\n",
        "\n",
        "As known, having a balanced dataset is important to train any model, in order to avoid a biased model.\n",
        "\n",
        "Assuming there are more negative cases for every disease, we take all positive cases and a close amount for the negative cases.\n",
        "\n",
        "\n",
        "*   Positive - \"Cardiomegaly\"\n",
        "\n",
        "*   Negative - \"No findings\"\n",
        "\n"
      ],
      "metadata": {
        "id": "BDmboOFcNEkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask = all_xray_df['Cardiomegaly'] == 1\n",
        "positive = all_xray_df.loc[mask]\n",
        "positive = positive.reset_index(drop=True)\n",
        "\n",
        "neg_mask = all_xray_df['No Finding'] == 1\n",
        "negative = all_xray_df.loc[neg_mask]\n",
        "negative = negative.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#chosen_idx = np.random.choice(len(negative), replace = False, size = int(n*1.2))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JsCKYfQPDbrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing the images ?????????\n",
        "  Normalizing the images can help the machine learning algorithm learn more effectively. One common way to normalize images is to scale the pixel values to have zero mean and unit range. Normalizing the data can help reduce the range of the input values. It can make the optimization process faster and more stable. Moreover, this process can reduce the model’s sensitivity to the scale of the input.\n",
        "Why is this better than another type of preprocessing the data?\n",
        "A different type of preprocessing the data is standardization, and is usually used when the input data is known to distribute close to a gaussian distribution. \n",
        "\n",
        "Our conclusions:\n",
        "In the case of this project using X-Ray images, we assume a skewed distribution. The images are grayscale and seem to contain relatively a large amount of pixels that are far from the average - white or very light gray indicates the presence of bones or more dense tissues, while dark gray or black represents the absence of it.\n",
        "Therefore we chose to use the normalization method for preprocessing the data, yet we might consider trying the other method, as experiments on the actual full dataset can be unexpected.\n"
      ],
      "metadata": {
        "id": "pqvX4n0W-gpS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBIyQlzW-mhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data to Train, Valid and Test\n",
        "\n",
        "In order to train the model we are going to use a separated dataset for training, validation and testing the model.\n",
        "80% of the data is meant to be used as training data for the model, to find patterns and get better in its inference.\n",
        "10% is meant to be used as a validation for the model, in order to check the quality of the model over different data as it is being trained.\n",
        "\n",
        "While training the model the separation can verify overfitting when occurs, and allow making conclusions of the algorithm's properties and behavior.\n",
        "\n",
        "Another 10% of the data is to be used for final testing of the trained model over a completely new data that hasn't been seen while training the model.\n"
      ],
      "metadata": {
        "id": "R3jMjZm1TdIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINSIZE = 0.86\n",
        "VALSIZE = 0.93\n",
        "\n",
        "\n",
        "p =len(positive)\n",
        "n = len(negative)\n",
        "N = n+p\n",
        "\n",
        "\n",
        "data = pd.concat([positive,negative]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "pos_train, pos_test, pos_val = positive.iloc[:int(TRAINSIZE*p)], positive.iloc[int(TRAINSIZE*p):int(VALSIZE*p)],positive.iloc[int(VALSIZE*p):]\n",
        "neg_train, neg_test, neg_val = negative.iloc[:int(TRAINSIZE*n)], negative.iloc[int(TRAINSIZE*n):int(VALSIZE*n)],negative.iloc[int(VALSIZE*n):n]\n",
        "data_train, data_test, data_val = data.iloc[:int(TRAINSIZE*N)], data.iloc[int(TRAINSIZE*N):int(VALSIZE*N)],data.iloc[int(VALSIZE*N):]\n",
        "\n",
        "data_train = data_train.reset_index(drop=True)\n",
        "pos_train = pos_train.reset_index(drop=True)\n",
        "neg_train = neg_train.reset_index(drop=True)\n",
        "\n",
        "data_test = data_test.reset_index(drop=True)\n",
        "pos_test = pos_test.reset_index(drop=True)\n",
        "neg_test = neg_test.reset_index(drop=True)\n",
        "\n",
        "data_val = data_val.reset_index(drop=True)\n",
        "pos_val = pos_val.reset_index(drop=True)\n",
        "neg_val = neg_val.reset_index(drop=True)\n",
        "pos_val\n"
      ],
      "metadata": {
        "id": "6Hw4CVW9S-hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming the Dataset to Tensors\n",
        "\n",
        "Our data is stored in collabs hard disc what cause high runtime, we will write a function that will store the train, val, test images in tensors. Using the images as tensors is also more efficient for model training."
      ],
      "metadata": {
        "id": "CZ2iZXl6pz7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_tensor(data,H,W):\n",
        "  n=len(data)\n",
        "  data_array = torch.zeros((n,H,W))\n",
        "  variables = torch.zeros((n,3))\n",
        "\n",
        "  for j in range(n):\n",
        "    if plt.imread(data['path'][j]).shape==(1024,1024):\n",
        "      data_array[j] = torch.tensor(resize(plt.imread(data['path'][j])[144:960,80:960],(H,W)))   \n",
        "    else:\n",
        "      data_array[j] = torch.tensor(resize(plt.imread(data['path'][j])[144:960,80:960,0],(H,W)))\n",
        "    \n",
        "    \n",
        "    variables[j,0] = data['Patient Age'][j]\n",
        "    variables[j,1] = data['Gender'][j]\n",
        "    variables[j,2] = data['position'][j]\n",
        "\n",
        "  return data_array, variables\n",
        "     \n"
      ],
      "metadata": {
        "id": "Brlm9IOrrFs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping the images ???\n",
        "\n",
        "in order to train the data we created some shapes for the images"
      ],
      "metadata": {
        "id": "1ssXy4VW_V7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H=224\n",
        "W=224\n",
        "\n",
        "pos_train_arr , vars_pos_train_arr = collect_tensor(pos_train,H,W)\n",
        "\n",
        "pos_test_arr , vars_pos_test_arr = collect_tensor(pos_test,H,W)\n",
        "\n",
        "pos_val_arr  , vars_pos_val_arr = collect_tensor(pos_val,H,W)\n",
        "\n",
        "neg_train_arr  , vars_neg_train_arr = collect_tensor(neg_train[:2500],H,W)\n",
        "\n",
        "neg_test_arr ,vars_neg_test_arr = collect_tensor(neg_test[:300],H,W)\n",
        "\n",
        "neg_val_arr  ,vars_neg_val_arr = collect_tensor(neg_val[:300],H,W)\n"
      ],
      "metadata": {
        "id": "vkXvT21jt-Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing the data we will try to look for different crops for the image, and different resizes to decide what transformation our good for the data."
      ],
      "metadata": {
        "id": "sbqdGl0xqQSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m, n =20, 5 \n",
        "fig, axs = plt.subplots(m, n, figsize= (n*3,m*4))\n",
        "for i in range(100):\n",
        "  plt.figure()\n",
        "  axs[i//n,i%n].imshow(resize(plt.imread(pos_train['path'][i])[144:960,80:960],(200,200)))\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "776aolL2x-ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = cv2.cvtColor(resize(plt.imread(pos_train['path'][0])[144:960,80:960],(200,200)),cv2.COLOR_GRAY2BGR)"
      ],
      "metadata": {
        "id": "-DG3NXkJ9OcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ????\n",
        "\n",
        "We will write a function which will generate positive/negative tensor batches for the accuracy check function."
      ],
      "metadata": {
        "id": "iUNgVkp7yqWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_tensor(data):\n",
        "   n=len(data)\n",
        "   xt = torch.zeros((n,224,224))\n",
        "   vars = torch.zeros((n,3))\n",
        "   for j in range(n):  \n",
        "      xt[j]=data[j]\n",
        "      vars[j][0]=data[j][1]\n",
        "      vars[j][1]=data[j][2]\n",
        "      vars[j][2]=data[j][3]\n",
        "      \n",
        "   xt=xt.reshape(n,224,224,1)\n",
        "   xt=torch.cat((xt,xt,xt),3)\n",
        "   xt=xt.reshape(n,3,224,224)\n",
        "   \n",
        "\n",
        "   return xt,vars          \n",
        "  "
      ],
      "metadata": {
        "id": "VVE3EhY2ni9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "vectorizing the gender column\n",
        "\n",
        "### bold text **TODO** we need to figure out how to demonstrate / prove correlation between gender and cardio.\n",
        "\n",
        "if there is none, remove the column "
      ],
      "metadata": {
        "id": "mL8B6XTzYJhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fu_mean = np.mean(all_xray_df['Follow-up #'])\n",
        "fu_mean_cardio = np.mean(all_xray_df.loc[all_xray_df['Cardiomegaly'] == True]['Follow-up #'])\n",
        "\n",
        "print(f'followup mean in dataset:{fu_mean}\\nfollowup mean for diagnosed patients:{fu_mean_cardio}\\n')"
      ],
      "metadata": {
        "id": "sjX1TNZDb5oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limitations\n",
        "In this project we were using a published dataset that contaings close to 45,000 X-Ray images along with some more information about each patient examined, and as well its history.\n",
        "\n",
        "The size of the dataset seemed to be large enough, though much of the data is not to be used. As found in the previous chapter, for the pathology \"Cardiomegaly\" there are only few thousands of images, so in order to use a perfectly balanced data it is needed to rely on a relatively small amount of images. As shown, we made it modifyable - potentially it is possible to reach more data, therefore it would be best to perfectly balance the positive and negative data.\n",
        "\n",
        "In addition, anothe limitation of the dataset that is later found was that some of the images were not in a very good quality, which seen in many of the false inferences shown later.\n",
        "\n",
        "Therefore, while considering this dataset as a practical source that is used to asses a potentially better training architecture."
      ],
      "metadata": {
        "id": "AC8m5nP_LCrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 🕸 **Network architecture**\n",
        "\n",
        "Now we will build the architecture of the model.\n",
        "\n",
        "important to mention that we used some image shapes: 1024X1024, 880X816, 224X224.\n",
        "\n",
        "**BLOCK 1:**\n",
        "\n",
        "\n",
        "\n",
        "*   Convolutional layer (nn.Conv2D(in_channels, num_hidden,kernel_size=(3,3), stride=(2,2)))\n",
        "\n",
        "*   Batch Normalization(num_hidden)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "*   Activation Function: nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**BLOCK 2:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Convolutional layer (nn.Conv2D(num_hidden, num_hidden * 2, kernel_size=(3,3), stride=(2,2))\n",
        "\n",
        "*   Activation Function: nn.ReLU()\n",
        "\n",
        "*   Batch Normalization(num_hidden * 2)\n",
        "*   MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "\n",
        "**BLOCK 3:**\n",
        "\n",
        "\n",
        "*   Convolutional layer (nn.Conv2D(num_hidden * 2, num_hidden * 4, kernel_size=(3,3), stride=(2,2))\n",
        "\n",
        "*   Activation Function: nn.ReLU()\n",
        "\n",
        "*   Batch Normalization(num_hidden * 4)\n",
        "\n",
        "\n",
        " \n",
        "**BLOCK 4:**\n",
        "\n",
        "\n",
        "*   Convolutional layer (nn.Conv2D(num_hidden * 4, num_hidden * 8, kernel_size=(3,3), stride=(2,2))\n",
        "\n",
        "*   Activation Function: nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "*   Batch Normalization(num_hidden * 8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**BLOCK 5:**\n",
        "\n",
        "\n",
        "*   FC layer(3 * 3 * 8 * num_hiddens,100)\n",
        "\n",
        "*   Activation Function: nn.Sigmoid()\n",
        "\n",
        "*   FC layer(100,20)\n",
        "\n",
        "*   Activation Function: nn.Sigmoid())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**BLOCK 6:**\n",
        "\n",
        "In this chapter we add the arguments: [Age,Gender,angle]\n",
        "                           \n",
        "\n",
        "*   FC layer(20 + num_vars, 2)\n",
        "*   nn.Sigmoid()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fAv9i6klgRHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input size: 1024x1024"
      ],
      "metadata": {
        "id": "8-do-TRc3dit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W,H = 1024,1024\n",
        "\n",
        "class CNN1(nn.Module):\n",
        "    def __init__(self, num_hiddens,num_vars):\n",
        "\n",
        "        \n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        H = 1024\n",
        "        W = 1024\n",
        "        in_channels = 1\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.block1 = nn.Sequential(nn.Conv2d(in_channels, num_hiddens, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.BatchNorm2d(num_hiddens),\n",
        "                                    nn.ReLU())\n",
        "        \n",
        "        self.block2 = nn.Sequential(nn.Conv2d(num_hiddens, num_hiddens*2, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.BatchNorm2d(num_hiddens*2),\n",
        "                                    nn.ReLU())\n",
        "\n",
        "        self.block3 = nn.Sequential(nn.Conv2d(num_hiddens*2, num_hiddens*4, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.BatchNorm2d(num_hiddens*4),\n",
        "                                    nn.ReLU())\n",
        "        \n",
        "        self.block4 = nn.Sequential(nn.Conv2d(num_hiddens*4, num_hiddens*8, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.BatchNorm2d(num_hiddens*8),\n",
        "                                    nn.ReLU())\n",
        "\n",
        "\n",
        "        self.fc_block1 = nn.Sequential(nn.Linear((W//16)*(H//16)*8*num_hiddens,100), #flatten the CNN output -> Block 5\n",
        "                                       nn.Sigmoid(),\n",
        "                                       nn.Linear(100,20),\n",
        "                                       nn.Sigmoid())\n",
        "        \n",
        "        self.fc_block2 =  nn.Sequential(nn.Linear(20 + num_vars, 10), #flatten the CNN output -> Block 6\n",
        "                                       nn.Sigmoid(),\n",
        "                                       nn.Linear(10,2),\n",
        "                                       nn.Sigmoid())\n",
        "         \n",
        "\n",
        "    def forward(self,x,vars):\n",
        "        \n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = x.contiguous().view(-1,(W//16)*(H//16)*8*self.num_hiddens) # reshape for tensor\n",
        "        x = self.fc_block1(x)\n",
        "        x= torch.cat((x,vars),1)\n",
        "        x = self.fc_block2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cAt7_Qpq3LHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k3X_VfXg3K2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input size: $224 𝗑 224$\n"
      ],
      "metadata": {
        "id": "93-srraEAlHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model= CNN(3,2)\n",
        "model.forward(lst_train[0])"
      ],
      "metadata": {
        "id": "Z_3IyJM29fI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluation function**\n",
        "\n",
        "We will test the accuracy of the positive and negative separately.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZRmqgPDJv-zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_saving  = '/content/gdrive/MyDrive/Intro_to_Deep_Learning/project/cardio'"
      ],
      "metadata": {
        "id": "EfQ9WDBNudCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(model, pos,neg,batch_size=50):\n",
        "    \"\"\"Compute the model accuracy on the data set. This function returns two\n",
        "    separate values: the model accuracy on the positive samples,\n",
        "    and the model accuracy on the negative samples.\n",
        "\n",
        "    Example Usage:\n",
        "\n",
        "    >>> model = CNN() # create untrained model\n",
        "    >>> pos_acc, neg_acc= get_accuracy(model, valid_data)\n",
        "    >>> false_positive = 1 - pos_acc\n",
        "    >>> false_negative = 1 - neg_acc\n",
        "    \"\"\"\n",
        "    len_pos= len(pos)\n",
        "    len_neg=len(neg)\n",
        "    model.eval()\n",
        "    acc_pos=0\n",
        "    acc_neg=0\n",
        "    H=224\n",
        "    W=224\n",
        "      \n",
        "    pos_correct = 0\n",
        "    for i in range(0, len_pos, batch_size):\n",
        "        if (i+batch_size)>len_pos:\n",
        "          break\n",
        "        acc_pos += batch_size\n",
        "        xs , var_xs = generate_batch_tensor(pos[i:i+batch_size])\n",
        "        if torch.cuda.is_available():\n",
        "            xs , var_xs = xs.cuda() , var_xs.cuda()\n",
        "        #zs = model(xs,var_xs)\n",
        "        zs = model(xs)\n",
        "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        pos_correct += (pred == 1).sum()\n",
        "    \n",
        "    neg_correct = 0\n",
        "    for i in range(0, len_pos, batch_size):\n",
        "        if (i+batch_size)>len_pos:\n",
        "            break\n",
        "        acc_neg += batch_size\n",
        "        xs , var_xs = generate_batch_tensor(neg[i:i+batch_size])\n",
        "        if torch.cuda.is_available():\n",
        "            xs , var_xs = xs.cuda() , var_xs.cuda()\n",
        "        #zs = model(xs,var_xs)\n",
        "        zs = model(xs)\n",
        "        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "        neg_correct += (pred == 0).sum()\n",
        "\n",
        "    return pos_correct/acc_pos, neg_correct/acc_neg"
      ],
      "metadata": {
        "id": "qXTjbGvG7Q2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training function**\n",
        "\n",
        "While training the different models we had to modify the training function multiple times.\n",
        "\n"
      ],
      "metadata": {
        "id": "NyJlsaoJITxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nn_train(model,\n",
        "              p_train = pos_train_arr,\n",
        "              n_train = neg_train_arr,\n",
        "              p_val = pos_val_arr,\n",
        "              n_val = neg_val_arr,\n",
        "              batch_size=10,\n",
        "              learning_rate=0.001,\n",
        "              weight_decay=0,\n",
        "              max_iters=1000,\n",
        "              checkpoint_path=None,\n",
        "              vars = False\n",
        "              ):\n",
        "#main training loop; choice of loss function; choice of optimizer\n",
        "  #print(\"hi\")\n",
        "\n",
        " \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  criterion = criterion.cuda()\n",
        "  \n",
        "  \n",
        "  optimizer = optim.SGD(model.parameters(),\n",
        "                           lr=learning_rate,\n",
        "                           weight_decay=weight_decay,\n",
        "                           momentum=0.9)\n",
        "  \n",
        "  iters, losses = [], []\n",
        "  iters_sub, train_accs_pos , train_accs_neg, val_accs_pos, val_accs_neg  = [], [] ,[],[],[]\n",
        "  \n",
        "  len_data= min(len(p_train),len(n_train))\n",
        "  acc_len_pos=0\n",
        "  acc_len_neg=0\n",
        "  H=224\n",
        "  W=224\n",
        "  n = 1501 # the number of iterations\n",
        "  while n < max_iters:\n",
        "      for i in range(0, len_data, batch_size):\n",
        "            if (i + batch_size) > len_data:\n",
        "                break\n",
        "            \n",
        "            model.train()\n",
        "            \n",
        "            #in each iteration, take batch_size / 2 positive samples and batch_size / 2 negative samples as our input for this batch\n",
        "            #pos_st,neg_st = np.ones(batch_size / 2), np.zeros(batch_size / 2)\n",
        "\n",
        "            xt=torch.zeros((2*batch_size,H,W))  #define empty tensor for batch\n",
        "            pos_st,neg_st = np.ones((batch_size)), np.zeros((batch_size))  #define batch//2 positive and batch//2 negative\n",
        "            st = np.concatenate((pos_st,neg_st),axis=0)\n",
        "            st = np.random.permutation(st)  #permutate the positive and negative outputs\n",
        "            st_or = torch.zeros((2*batch_size,2)) #define output tensor -  negative : [1,0], positive : [0,1] \n",
        "            vars = torch.zeros((2*batch_size,3)) # define tensor for variables : [Age, gender , Angle]\n",
        "            \n",
        "            #building the batch input tensors\n",
        "            \n",
        "            pos_idx=i\n",
        "            neg_idx=i\n",
        "            j=-1\n",
        "                     \n",
        "            while( pos_idx+neg_idx<2*i+2*batch_size):  \n",
        "              j+=1 \n",
        "              if st[j]:\n",
        "                xt[j]=p_train[pos_idx]\n",
        "                st_or[j,1]=1\n",
        "                #vars[j][0]=p_train[pos_idx]\n",
        "                #vars[j][1]=p_train[pos_idx]\n",
        "                #vars[j][2]=p_train[pos_idx]\n",
        "                pos_idx+=1\n",
        "\n",
        "              else:\n",
        "                xt[j]=n_train[neg_idx]\n",
        "                st_or[j,0]=1\n",
        "                #vars[j][0]=n_train[neg_idx]\n",
        "                #vars[j][1]=n_train[neg_idx]\n",
        "                #vars[j][2]=n_train[neg_idx]\n",
        "                neg_idx+=1\n",
        "              \n",
        "          \n",
        "            \n",
        "            #conversion from numpy arrays to PyTorch tensors, making sure that the input has dimensions  N×C×H×W  (known as NCHW tensor)\n",
        "            #.. where  N  is the number of images batch size,  C  is the number of channels,  H  is the height of the image, and  W  is the width of the image.\n",
        "            \n",
        "\n",
        "            xt=xt.reshape(2*batch_size,H,W,1)\n",
        "            xt = torch.cat((xt,xt,xt),3)  #GRAYSCALE to RGB for training the resnet18,VGG16 models\n",
        "            xt=xt.reshape(2*batch_size,3,H,W)\n",
        "            \n",
        "    \n",
        "            if torch.cuda.is_available():\n",
        "                xt , vars , st = xt.cuda() , vars.cuda() , st_or.cuda()\n",
        "            \n",
        "            #zs = model(xt,vars)  # forwarding the model\n",
        "            zs = model(xt)\n",
        "            #print('zs=', zs.shape, zs)  \n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(zs, st)\n",
        "            loss.backward()\n",
        "            losses.append(float(loss)/batch_size) \n",
        "            optimizer.step()\n",
        "            \n",
        "\n",
        "            #after every epoch, report the accuracies for the training set and validation set\n",
        "            if n % 100==0:\n",
        "                iters_sub.append(n)\n",
        "                train_cost = float(loss.detach().cpu().numpy())\n",
        "                train_acc_pos,train_acc_neg  = get_accuracy(model, p_train[:300],n_train,batch_size)\n",
        "                train_accs_pos.append(train_acc_pos)\n",
        "                train_accs_neg.append(train_acc_neg)\n",
        "                val_acc_pos , val_acc_neg = get_accuracy(model, p_val,n_val,batch_size)\n",
        "                val_accs_pos.append(val_acc_pos)\n",
        "                val_accs_neg.append(val_acc_neg)\n",
        "                print(\"Iter %d. [Val pos Acc %.0f%%] [Val neg Acc %.0f%%] [Train pos Acc %.0f%%,Train neg Acc %.0f%%, Loss %f]\" % (n, val_acc_pos * 100,val_acc_neg * 100, train_acc_pos * 100, train_acc_neg * 100, train_cost))\n",
        "\n",
        "                if (n>500 and n % 400==0 and checkpoint_path is not None):  #save model\n",
        "                    n_path = checkpoint_path + f\"{n}\"\n",
        "                    torch.save(model.state_dict(), n_path.format(n))\n",
        "            # increment the iteration number\n",
        "            n += 1\n",
        "\n",
        "            if n > max_iters:\n",
        "              return model,losses, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg\n",
        "        \n",
        "            \n",
        "            \n",
        "\n",
        "\n",
        "          #track the training curve information and plot the training curve\n",
        "        \n",
        "              \n",
        "  return model,losses, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg"
      ],
      "metadata": {
        "id": "cxUWcxaHJYHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JSJGTSpWEL09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GoCAg_fGEOEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarks\n",
        "\n",
        "here we will import real-world state of the art models that are well known for their good detection accuracy in many test cases and some, specifically on the NIH dataset.\n",
        "\n",
        "For this project, reaching an accuracy of more than 70% is determined to be a good result that would be potentially rise with bigger and higher-quality dataset as described above."
      ],
      "metadata": {
        "id": "nXgHrRzWsaNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alexnet"
      ],
      "metadata": {
        "id": "R4cDPllls8V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes: int = 2) -> None:\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        #self.block = nn.Linear(4099, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor: #add \"vars\" argument for variables\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        #x = torch.cat((x,vars),1)\n",
        "        #x = self.block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XKvP469jKOpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  alexnet_model = AlexNet().cuda()\n",
        "else:\n",
        "  alexnet_model = AlexNet()"
      ],
      "metadata": {
        "id": "VPSiMTjsbFrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_model,losses, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg  = nn_train(alexnet_model,p_train=pos_train,n_train=neg_train[:4000],batch_size=30,learning_rate=0.0002,\n",
        "              weight_decay=0,\n",
        "              max_iters=1000,\n",
        "              checkpoint_path=path_saving+'_alexnet2_')"
      ],
      "metadata": {
        "id": "HCdP7Y-tboDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  alexnet_model3 = AlexNet().cuda()\n",
        "else:\n",
        "  alexnet_model3 = AlexNet()"
      ],
      "metadata": {
        "id": "129CaJrJwN5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_model3,alex_losses, alex_train_accs_pos, alex_train_accs_neg, alex_val_accs_pos, alex_val_accs_neg  = nn_train(alexnet_model3,p_train=pos_train,n_train=neg_train[:4000],batch_size=50,learning_rate=0.0002,\n",
        "              weight_decay=0,\n",
        "              max_iters=800,\n",
        "              checkpoint_path=path_saving+'_alexnet3_')"
      ],
      "metadata": {
        "id": "0IvAeYTvu1HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_model31.load_state_dict(torch.load('/content/gdrive/MyDrive/Intro_to_Deep_Learning/project/cardio_alexnet3_900'))\n",
        "alexnet_model31,alex_losses2, alex_train_accs_pos2, alex_train_accs_neg2, alex_val_accs_pos2, alex_val_accs_neg2  = nn_train(alexnet_model3,p_train=pos_train,n_train=neg_train[:4000],batch_size=50,learning_rate=0.00005,\n",
        "              weight_decay=0,\n",
        "              max_iters=1300,\n",
        "              checkpoint_path=path_saving+'_alexnet3_')"
      ],
      "metadata": {
        "id": "fCVQAIx5P-77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet_model.load_state_dict(torch.load('/content/gdrive/MyDrive/Intro_to_Deep_Learning/project/cardio_alexnet_1200'))\n",
        "alexnet_model,losses2, train_accs_pos2, train_accs_neg2, val_accs_pos2, val_accs_neg2  = nn_train(alexnet_model,pos_train=pos_train,neg_train=neg_train[:4000],batch_size=30,learning_rate=0.00005,\n",
        "              weight_decay=0,\n",
        "              max_iters=1500,\n",
        "              checkpoint_path=path_saving+'_alexnet_')"
      ],
      "metadata": {
        "id": "zaM5gZABJcL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  resnet18_model = torchvision.models.resnet18(num_classes=2).cuda()\n",
        "else:\n",
        "  resnet18_model = torchvision.models.resnet18(num_classes=2)"
      ],
      "metadata": {
        "id": "CIjI8Ryt1oJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### performance and insights\n",
        "in the architecture above we see a high accuracy results, and we hyperparameters in our model"
      ],
      "metadata": {
        "id": "BxW83VGytLd_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet "
      ],
      "metadata": {
        "id": "BBhG1pzAufVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bJwDa01VufPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_model,res_losses, res_train_accs_pos, res_train_accs_neg, res_val_accs_pos, res_val_accs_neg  = nn_train(resnet18_model,p_train=pos_train,n_train=neg_train[:2500],p_val=pos_val,n_val=neg_val,batch_size=30,learning_rate=0.01,\n",
        "              weight_decay=0,\n",
        "              max_iters=1200,\n",
        "              checkpoint_path=path_saving+'_resnet2_')"
      ],
      "metadata": {
        "id": "-mCPwZmTGrxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_model,res_losses, res_train_accs_pos, res_train_accs_neg, res_val_accs_pos, res_val_accs_neg  = nn_train(resnet18_model,p_train=pos_train,n_train=neg_train[:2400],batch_size=40,learning_rate=0.001,\n",
        "              weight_decay=0.0001,\n",
        "              max_iters=1200,\n",
        "              checkpoint_path=path_saving+'_resnet2_')"
      ],
      "metadata": {
        "id": "FqPaf9vJqI7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_model,res_losses2, res_train_accs_pos2, res_train_accs_neg2, res_val_accs_pos2, res_val_accs_neg2  = nn_train(resnet18_model,p_train=pos_train,n_train=neg_train[:2400],batch_size=70,learning_rate=0.001,\n",
        "              weight_decay=0.0001,\n",
        "              max_iters=1600,\n",
        "              checkpoint_path=path_saving+'_resnet2_')"
      ],
      "metadata": {
        "id": "jdQ1eDyE-Xbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_model,res_losses3, res_train_accs_pos3, res_train_accs_neg3, res_val_accs_pos3, res_val_accs_neg3  = nn_train(resnet18_model,p_train=pos_train,n_train=neg_train[:2400],batch_size=70,learning_rate=0.001,\n",
        "              weight_decay=0.0001,\n",
        "              max_iters=2300,\n",
        "              checkpoint_path=path_saving+'_resnet2_')"
      ],
      "metadata": {
        "id": "5DrnI7YZyTOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### performance and insights"
      ],
      "metadata": {
        "id": "jfN8Bxg7w4Sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG_16\n"
      ],
      "metadata": {
        "id": "_LUG4nafw_8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  vgg16_model = torchvision.models.vgg16(num_classes=2).cuda()\n",
        "else:\n",
        "  vgg16_model = torchvision.models.vgg16(num_classes=2)"
      ],
      "metadata": {
        "id": "zgAUACqP6EMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model,vgg_losses, vgg_train_accs_pos, vgg_train_accs_neg, vgg_val_accs_pos, vgg_val_accs_neg  = nn_train(vgg16_model,p_train=pos_train_arr,n_train=neg_train_arr,p_val=pos_val_arr,n_val=neg_val_arr,batch_size=80,learning_rate=0.001,\n",
        "              weight_decay=0,\n",
        "              max_iters=1500,\n",
        "              checkpoint_path=path_saving+'_VGG16_')"
      ],
      "metadata": {
        "id": "1z0shh6f6AKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model,vgg_losses2, vgg_train_accs_pos2, vgg_train_accs_neg2, vgg_val_accs_pos2, vgg_val_accs_neg2  = nn_train(vgg16_model,p_train=pos_train_arr,n_train=neg_train_arr,p_val=pos_val_arr,n_val=neg_val_arr,batch_size=100,learning_rate=0.001,\n",
        "              weight_decay=0,\n",
        "              max_iters=4000,\n",
        "              checkpoint_path=path_saving+'_VGG16_')"
      ],
      "metadata": {
        "id": "jRQUK0q184da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best_resnet18_model =torchvision.models.resnet18(num_classes=2).cuda()\n",
        "#best_resnet18_model.load_state_dict(torch.load('/content/gdrive/MyDrive/Intro_to_Deep_Learning/project/cardio_resnet_900'))\n",
        "#best_resnet18_model.eval()\n",
        "test_pos_res, test_neg_res = get_accuracy(resnet18_model,pos_val,neg_val,10)\n",
        "print(f'positive test accuracy: {test_pos_res*100}')\n",
        "print(f'negative test accuracy: {test_neg_res*100}')"
      ],
      "metadata": {
        "id": "9ClxTyLdZ5yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💪 **Training the Model: Trial & Error**"
      ],
      "metadata": {
        "id": "nD4WaLANRgPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sanity check**:\n",
        "\n",
        "we will try to memorize the data for 10 positive and 10 negative samples"
      ],
      "metadata": {
        "id": "AWxHCgEI1PH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  CNN_20 = CNN(3,2).cuda()\n",
        "else:\n",
        "  CNN_20 = CNN(3,2)\n",
        "\n",
        "history_20 = nn_train(CNN_20,pos_train=pos_train[:20],neg_train=neg_train[:20],batch_size=10,learning_rate=0.0001,\n",
        "              weight_decay=0,\n",
        "              max_iters=700,\n",
        "              checkpoint_path=None)"
      ],
      "metadata": {
        "id": "kZzUh6afe_KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **First training**\n",
        "\n",
        "Now we will train the model for the first time. For curiosity, at first we train the images with 1024X1024 size to see how close the results we get.\n"
      ],
      "metadata": {
        "id": "PIQ-lgCWmR-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  CNN_cardio = CNN(3,2).cuda()\n",
        "else:\n",
        "  CNN_cardio = CNN(3,2)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "WM944o98si9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_cardio,losses, train_accs_pos, train_accs_neg, val_accs_pos, val_accs_neg  = nn_train(CNN_cardio,batch_size=10,learning_rate=0.0001,\n",
        "              weight_decay=0,\n",
        "              max_iters=4000,\n",
        "              checkpoint_path=path_saving+\"original_\")"
      ],
      "metadata": {
        "id": "X_uhYUhBtcf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overcoming Overfitting\n",
        "We see that we got an **overfitting** because the model memorized the training data but have a poor validation prediction. we added several munipulations to the images:\n",
        "1. we see that there is some area that have no information so we cropped the images.\n",
        "2. for the overfitting we added a max pooling layers to make model more robustic, and we shuffle the training data everytime it gets to an end to make it harder for the model to memorize it.\n",
        "\n",
        "Now we will train to give our model a second try."
      ],
      "metadata": {
        "id": "QOepVCX64isl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(CNN_cardio.state_dict(), (path_saving+\"cardio_10_iter\").format(n))"
      ],
      "metadata": {
        "id": "JjldqwVh-0Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN2(nn.Module):\n",
        "    def __init__(self, num_hiddens,num_vars):\n",
        "\n",
        "        \n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.H = 224\n",
        "        self.W = 224\n",
        "        in_channels = 1\n",
        "        self.num_hiddens = num_hiddens\n",
        "        self.block1 = nn.Sequential(nn.Conv2d(in_channels, num_hiddens, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.BatchNorm2d(num_hiddens),\n",
        "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.block2 = nn.Sequential(nn.Conv2d(num_hiddens, num_hiddens*2, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.BatchNorm2d(num_hiddens*2),\n",
        "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.block3 = nn.Sequential(nn.Conv2d(num_hiddens*2, num_hiddens*4, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.BatchNorm2d(num_hiddens*4))\n",
        "        \n",
        "        self.block4 = nn.Sequential(nn.Conv2d(num_hiddens*4, num_hiddens*8, kernel_size=(3,3), stride=(2,2),padding=(1,1)),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.BatchNorm2d(num_hiddens*8))\n",
        "\n",
        "\n",
        "        self.fc_block1 = nn.Sequential(nn.Linear(3*3*8*num_hiddens,100), #flatten the CNN output\n",
        "                                       nn.Sigmoid(),\n",
        "                                       nn.Linear(100,20),\n",
        "                                       nn.Sigmoid())\n",
        "        \n",
        "        self.fc_block2 =  nn.Sequential(nn.Linear(20 + num_vars, 2), #flatten the CNN output\n",
        "                                       nn.Sigmoid())\n",
        "        \n",
        "\n",
        "    def forward(self,x,vars):\n",
        "        \n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = x.contiguous().view(-1,3*3*8*self.num_hiddens) # reshape for tensor\n",
        "\n",
        "        x = self.fc_block1(x)\n",
        "        #x= torch.cat((x,vars),1)\n",
        "        x = self.fc_block2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "WkpR6yFEgqU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  CNN_cardio2 = CNN(3,2).cuda()\n",
        "else:\n",
        "  CNN_cardio2 = CNN(3,2)"
      ],
      "metadata": {
        "id": "ObhMoRfpdki9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  CNN_cardio_shuffled = CNN(3,2).cuda()\n",
        "else:\n",
        "  CNN_cardio_shffled = CNN(3,2)\n",
        "  \n"
      ],
      "metadata": {
        "id": "Hm1_a2f7SxSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_cardio_shuffled,losses5, train_accs_pos5, train_accs_neg5, val_accs_pos5, val_accs_neg5  = nn_train(CNN_cardio_shuffled,batch_size=10,learning_rate=0.0001,\n",
        "              weight_decay=0,\n",
        "              max_iters=2500,\n",
        "              checkpoint_path=path_saving+\"_shffled\")"
      ],
      "metadata": {
        "id": "3ch6eAw_S9CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_cardio_shuffled,losses6, train_accs_pos6, train_accs_neg6, val_accs_pos6, val_accs_neg6  = nn_train(CNN_cardio_shuffled,batch_size=10,learning_rate=0.0003,\n",
        "              weight_decay=0,\n",
        "              max_iters=5000,\n",
        "              checkpoint_path=path_saving+\"_shffled\")"
      ],
      "metadata": {
        "id": "dkAK9mPUJOUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_cardio_shuffled,losses7, train_accs_pos7, train_accs_neg7, val_accs_pos7, val_accs_neg7  = nn_train(CNN_cardio_shuffled,batch_size=10,learning_rate=0.0005,\n",
        "              weight_decay=0,\n",
        "              max_iters=7500,\n",
        "              checkpoint_path=path_saving+\"_shffled\")"
      ],
      "metadata": {
        "id": "YPpHTQsdqJP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First attempt analysis\n",
        "\n",
        "we got to an average of **74%** of accuracy and now wee see that its hard for the model to memorize the data.\n"
      ],
      "metadata": {
        "id": "ywxWPlUa3rKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we tried to train the model to predict \"with cardiomegaly\" vs \"without cardiomegaly\" but there is some correlation between other diseases that make it harder for the model to learn it, so we will try to change the prediction to \"with cardiomegaly\" vs \"no findings\""
      ],
      "metadata": {
        "id": "gwWC1joW6HPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.function_base import linspace\n",
        "\n",
        "def plot_analisys(model, history)\n",
        "  plt.figure()\n",
        "  \n",
        "  # devide to sections\n",
        "  res_train_accs_pos,res_train_accs_neg, res_val_accs_pos, res_val_accs_neg = history\n",
        "  N = range(len(res_losses))\n",
        "\n",
        "  fig, axs = plt.subplots(5,figsize=(15, 15))\n",
        "\n",
        "  axs[0].plot(N, [30*res_losses[i] for i in N])\n",
        "  axs[0].set_title('losses')\n",
        "\n",
        "  N = range(len(res_train_accs_pos))\n",
        "  axs[1].plot(N, res_train_accs_pos)\n",
        "  axs[1].set_title('train positive accuracy ')\n",
        "  axs[2].plot(N, res_train_accs_neg,'tab:orange')\n",
        "  axs[2].set_title('train negative accuracy')\n",
        "  axs[3].plot(N, res_val_accs_pos, 'tab:green')\n",
        "  axs[3].set_title('validation positive accuracy')\n",
        "  axs[4].plot(N, res_val_accs_neg, 'tab:red')\n",
        "  axs[4].set_title('validation negative accuracy')\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "1ph4tbp-uWRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Attempt on a Cleaner Data"
      ],
      "metadata": {
        "id": "wlWFP363pfmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  NofindXcardio2 = CNN(3,3).cuda()\n",
        "else:\n",
        "  NofindXcardio2 = CNN(3,3)"
      ],
      "metadata": {
        "id": "idGs0vuDemQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NofindXcardio2,losses2, train_accs_pos2, train_accs_neg2, val_accs_pos2, val_accs_neg2  = nn_train(NofindXcardio2,pos_train=pos_train,neg_train=neg_train[:4000],batch_size=30,learning_rate=0.0002,\n",
        "              weight_decay=0,\n",
        "              max_iters=2500,\n",
        "              checkpoint_path=path_saving+'No_findXCardio2_')"
      ],
      "metadata": {
        "id": "4NgCbHroepzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NofindXcardio21,losses21, train_accs_pos21, train_accs_neg21, val_accs_pos21, val_accs_neg21  = nn_train(NofindXcardio2,pos_train=pos_train,neg_train=neg_train[:4000],batch_size=30,learning_rate=0.0002,\n",
        "              weight_decay=0,\n",
        "              max_iters=3200,\n",
        "              checkpoint_path=path_saving+'No_findXCardio2_')"
      ],
      "metadata": {
        "id": "gVtwSHG0OKqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NofindXcardio22,losses22, train_accs_pos22, train_accs_neg22, val_accs_pos22, val_accs_neg22  = nn_train(NofindXcardio2,pos_train=pos_train,neg_train=neg_train[:4000],batch_size=30,learning_rate=0.0002,\n",
        "              weight_decay=0,\n",
        "              max_iters=4000,\n",
        "              checkpoint_path=path_saving+'No_findXCardio2_')"
      ],
      "metadata": {
        "id": "oOnKnyAOYnLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2nd attempt Results & analysis\n",
        "now we got validation accuracy of 77.5%\n",
        "we will print to images that the model didn't predict right."
      ],
      "metadata": {
        "id": "klD5FiS9tABf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**False negative images**"
      ],
      "metadata": {
        "id": "ctl6PMY1tfJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int(0.9*p),int(0.93*p)):\n",
        "  NofindXcardio22.eval()\n",
        "  xt=torch.Tensor(plt.imread(pos_val['path'][i])[144:960,80:960]).cuda()\n",
        "  if xt.shape==(816,880):\n",
        "    xt = xt.reshape(1,1,816,880)\n",
        "  else:  \n",
        "    xt = xt[:,:,0].reshape(1,1,816,880)\n",
        "  finding=NofindXcardio22(xt,torch.Tensor([pos_val['Patient Age'][i],pos_val['Gender'][i],pos_val['position'][i]]).reshape(1,3).cuda())\n",
        "  if finding[0][0]>finding[0][1]:\n",
        "    plt.figure()\n",
        "    plt.imshow(plt.imread(pos_val['path'][i])[144:960,80:960])\n",
        "    plt.title(str(finding))"
      ],
      "metadata": {
        "id": "wN0uAlu-kquq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**False positive images**"
      ],
      "metadata": {
        "id": "R57pZ4bUtnL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(int(0.9*n),int(0.901*n)):\n",
        "  NofindXcardio22.eval()\n",
        "  xt=torch.Tensor(plt.imread(neg_val['path'][i])[144:960,80:960]).cuda()\n",
        "  if xt.shape==(816,880):\n",
        "    xt = xt.reshape(1,1,816,880)\n",
        "  else:  \n",
        "    xt = xt[:,:,0].reshape(1,1,816,880)\n",
        "  finding=NofindXcardio22(xt,torch.Tensor([neg_val['Patient Age'][i],neg_val['Gender'][i],neg_val['position'][i]]).reshape(1,3).cuda())\n",
        "  if finding[0][0]<finding[0][1]:\n",
        "    plt.figure()\n",
        "    plt.imshow(plt.imread(neg_val['path'][i])[144:960,80:960])\n",
        "    plt.title(str(finding))"
      ],
      "metadata": {
        "id": "r65ZKFUWrVO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "until now we tried to train the model with full sized cropped image, now we will try to resize it to shape (200,200) and train the model with the resized image size.\n",
        "unfortunatelly when we tried to train the resized images with our model we got less accurate results than in the models we already trained so we didnt insert it to the report.\n",
        "\n",
        "From now on we will try to use pretrained models: AlexNet, Resnet18 and VGG16."
      ],
      "metadata": {
        "id": "VV9fk1iF4CIr"
      }
    }
  ]
}